{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "18df911a",
      "metadata": {
        "id": "18df911a"
      },
      "source": [
        "# Assignment 4: CNN and ResNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9dfe137",
      "metadata": {
        "id": "c9dfe137"
      },
      "source": [
        "We first import all we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "35b58be1",
      "metadata": {
        "id": "35b58be1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as DS\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.cuda.is_available()\n",
        "cuda = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "39963878",
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'uw-cs480-winter23/'\n",
        "image_path = 'uw-cs480-winter23/noisy-images/noisy-images/'\n",
        "\n",
        "def load_data():\n",
        "    train_df = pd.read_csv(file_path + 'train.csv')\n",
        "    test_df = pd.read_csv(file_path + 'test.csv')\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "210d275d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21627\n",
            "21583\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = load_data()\n",
        "data_size = len(train_df)\n",
        "print(data_size)\n",
        "\n",
        "# remove all free gifts\n",
        "train_df = train_df[train_df.category != 'Free Gifts']\n",
        "data_size = len(train_df)\n",
        "print(data_size)\n",
        "\n",
        "categories = train_df.category.unique()\n",
        "category_d = {k: v for v, k in enumerate(categories)}\n",
        "\n",
        "genders = train_df.gender.unique()\n",
        "gender_d = {k: v for v, k in enumerate(genders)}\n",
        "num_genders = len(genders)\n",
        "\n",
        "baseColours = train_df.baseColour.unique()\n",
        "baseColour_d = {k: v for v, k in enumerate(baseColours)}\n",
        "num_baseColours = len(baseColours)\n",
        "\n",
        "seasons = train_df.season.unique()\n",
        "season_d = {k: v for v, k in enumerate(seasons)}\n",
        "num_seasons = len(seasons)\n",
        "\n",
        "usages = train_df.usage.unique()\n",
        "usage_d = {k: v for v, k in enumerate(usages)}\n",
        "num_usages = len(usages)\n",
        "\n",
        "# training data\n",
        "\n",
        "train_df.replace(\n",
        "    {'category': category_d}\n",
        "    , inplace=True\n",
        ")\n",
        "\n",
        "# testing data\n",
        "\n",
        "test_df.replace(\n",
        "    {'category': category_d}\n",
        "    , inplace=True\n",
        ")\n",
        "\n",
        "id_target = train_df[['id', 'category']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "188ee827",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = id_target[:, 1]\n",
        "train_id = id_target[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3378cd2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels_onehot = []\n",
        "\n",
        "for (idx, cate) in enumerate(train_labels):\n",
        "    train_labels_onehot.append(np.eye(26)[cate])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "77d04612",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\zhc17\\AppData\\Local\\Temp\\ipykernel_49016\\4178741031.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_id_target = np.array([train_id, train_labels_onehot]).T\n"
          ]
        }
      ],
      "source": [
        "# id_target[:, 1] = train_labels_onehot\n",
        "\n",
        "new_id_target = np.array([train_id, train_labels_onehot]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b2646271",
      "metadata": {
        "id": "b2646271"
      },
      "outputs": [],
      "source": [
        "transformer = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "class Image_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, id_target, folder=image_path):\n",
        "        self.id_target = id_target\n",
        "        self.folder = folder\n",
        "        self.transform = transformer\n",
        "    def __len__(self):\n",
        "        return len(self.id_target)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.folder + str(self.id_target[idx][0]) + '.jpg'\n",
        "        image = Image.open(img_name)\n",
        "        result = self.transform(image)\n",
        "\n",
        "        return result, self.id_target[idx][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "26d14a25",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_image = Image_Dataset(new_id_target)\n",
        "test_image = Image_Dataset(new_id_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7911aeac",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_set, test_set = train_test_split(train_image, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "32491c47",
      "metadata": {
        "id": "32491c47"
      },
      "outputs": [],
      "source": [
        "# create data loaders\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "485c4ae6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 3, 80, 60])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in train_loader:\n",
        "    print(images.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6b200ab5",
      "metadata": {
        "id": "6b200ab5"
      },
      "outputs": [],
      "source": [
        "class ANNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*60*80, 128)\n",
        "        self.fc2 = nn.Linear(128, 26)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*60*80)  # Flatten the input image\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2aca82",
      "metadata": {
        "id": "7a2aca82"
      },
      "source": [
        "### Task 2: Implementing the Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a36eb60e",
      "metadata": {
        "id": "a36eb60e"
      },
      "outputs": [],
      "source": [
        "def test(model, loss_function, device):\n",
        "    # we first move our model to the configured device\n",
        "    model = model.to(device = device)\n",
        "\n",
        "    # we make sure we are not tracking gradient\n",
        "    # gradient is used in training, we do not need it for test\n",
        "    with torch.no_grad():\n",
        "        risk = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # loop over test mini-batches\n",
        "        for i, (images, labels) in enumerate(test_loader):\n",
        "            # reshape labels to have the same form as output\n",
        "            # make sure labels are of torch.float32 type\n",
        "            labels = labels.float()\n",
        "\n",
        "            # move tensors to the configured device\n",
        "            images = images.to(device = device)\n",
        "            labels = labels.to(device = device)\n",
        "\n",
        "            # forward pass\n",
        "            outputs = model(images)\n",
        "            loss = loss_function(outputs, labels)\n",
        "\n",
        "            \n",
        "            # compute the fraction of correctly predicted labels\n",
        "            # correct_predict = torch.sum(labels- outputs).item()\n",
        "            predicted_classes = torch.argmax(labels, dim=1)\n",
        "            selected_probs = outputs[torch.arange(len(outputs)), predicted_classes]\n",
        "\n",
        "            risk += loss.item()\n",
        "            accuracy += selected_probs.mean().item()\n",
        "\n",
        "        # average test risk and accuracy over the whole test dataset\n",
        "        test_risk = risk/i\n",
        "        test_accuracy = accuracy/i\n",
        "\n",
        "    return test_risk, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2994f887",
      "metadata": {
        "id": "2994f887"
      },
      "source": [
        "Now test your untrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0673483d",
      "metadata": {
        "id": "0673483d"
      },
      "source": [
        "### Task 3: Implementing Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "88ff3838",
      "metadata": {
        "id": "88ff3838"
      },
      "outputs": [],
      "source": [
        "def train(model, num_epochs, device):\n",
        "    # we first move our model to the configured device\n",
        "    model = model.to(device = device)\n",
        "\n",
        "    # set loss to binary CE\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    # Set optimizer with optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Initiate the values\n",
        "    train_risk = []\n",
        "    test_risk = []\n",
        "    test_accuracy = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # training risk in one epoch\n",
        "        risk = 0\n",
        "\n",
        "        # loop over training data\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "            # reshape labels to have the same form as output\n",
        "            # make sure labels are of torch.float32 type\n",
        "            labels = labels.float()\n",
        "\n",
        "            # move tensors to the configured device\n",
        "            images = images.to(device = device)\n",
        "            labels = labels.to(device = device)\n",
        "\n",
        "            # forward pass\n",
        "            outputs = model(images)\n",
        "            loss = loss_function(outputs, labels)\n",
        "\n",
        "            # collect the training loss\n",
        "            risk += loss.item()\n",
        "\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # use auto-grad (just 1 line)\n",
        "\n",
        "            # one step of gradient descent\n",
        "            optimizer.step()\n",
        "\n",
        "        # test out model after update by the optimizer\n",
        "        risk_epoch, accuracy_epoch = test(model, loss_function, device)\n",
        "\n",
        "        # collect losses and accuracy\n",
        "        train_risk.append(risk/i)\n",
        "        test_risk.append(risk_epoch)\n",
        "        test_accuracy.append(accuracy_epoch)\n",
        "\n",
        "        # we can print a message every second epoch\n",
        "        if (epoch+1) % 2 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_risk[-1]}, Test Loss: {test_risk[-1]}, Test Accuracy: {test_accuracy[-1]}\")\n",
        "\n",
        "    # plot the losses\n",
        "    plt.plot([i+1 for i in range(num_epochs)], train_risk, label=\"train\")\n",
        "    plt.plot([i+1 for i in range(num_epochs)], test_risk, label=\"test\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # plot the accuracy\n",
        "    plt.plot([i+1 for i in range(num_epochs)], test_accuracy)\n",
        "    plt.show()\n",
        "\n",
        "    return train_risk, train_risk, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b92d3fb1",
      "metadata": {
        "id": "b92d3fb1"
      },
      "source": [
        "Now, we can train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "76888d9b",
      "metadata": {
        "id": "76888d9b"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m train_risk, train_risk, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, num_epochs, device)\u001b[0m\n\u001b[0;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# collect the training loss\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m risk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[0;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "model = ANNClassifier()\n",
        "\n",
        "if torch.has_cuda:\n",
        "    device = \"cuda\"\n",
        "elif torch.has_mps:\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "train_risk, train_risk, test_accuracy = train(model, 20, device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PyCharm (kaggle)",
      "language": "python",
      "name": "pycharm-d89a0e8e"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
